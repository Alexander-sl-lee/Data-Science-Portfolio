{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Project 4\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Importing modules**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Scraping**\n",
    "\n",
    "Unfortunately since I'm not too familiar with scrapy and jupyter notebook, I dont know how to integrate the scrapy spider into the notebook. However, the below cell contains the code for spider scraper\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy, re\n",
    "from bs4 import BeautifulSoup\n",
    "from scrapy.spiders import CrawlSpider, Rule\n",
    "from scrapy.linkextractors import LinkExtractor\n",
    "\n",
    "class IndeedSpider(CrawlSpider):\n",
    "    name = 'indeed'\n",
    "    allowed_domains = ['au.indeed.com']\n",
    "\n",
    "    pay = 60000\n",
    "\n",
    "    urls = ['https://au.indeed.com/jobs?q=data+scientist+%24{}+-+%24{}'.format(x-10000, x) for x in range(50000,210000,10000)]\n",
    "\n",
    "    start_urls = urls\n",
    "\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(\"start\\=.*$\"), callback='parse_item', follow = True),\n",
    "    )    \n",
    "\n",
    "    def parse_item(self, response):\n",
    "        self.log('------------------------------------')\n",
    "        self.log('I just visited: ' + response.url)\n",
    "        self.log('------------------------------------')\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        divs = soup.find_all(\"div\", class_ = [\"row\", \"result\"])\n",
    "\n",
    "\n",
    "        for job in divs:\n",
    "            \n",
    "            item = {}\n",
    "\n",
    "            item[\"id\"] = job.get(\"id\")\n",
    "\n",
    "            try:\n",
    "                item[\"company\"] = job.find(\"span\", class_ = \"company\").text.strip(\"\\n\").strip()\n",
    "            except AttributeError:\n",
    "                item[\"company\"] = None\n",
    "                \n",
    "            item[\"pay\"] = re.search('([0-9]*)&start', response.url).group(1)\n",
    "\n",
    "            item[\"title\"] = job.a.get(\"title\")\n",
    "\n",
    "            item[\"loc\"]= job.find(\"span\", class_ =\"location\").text\n",
    "\n",
    "            job_summ_page = job.get(\"data-jk\")\n",
    "            next_page_url = \"https://au.indeed.com/viewjob?jk={}&from=tp-serp&tk=1c2i82l0a102q7vk\".format(job_summ_page)\n",
    "            yield scrapy.Request(url = next_page_url, callback = self.parse_summ, meta=dict(item=item))\n",
    "\n",
    "    def parse_summ(self, response):\n",
    "        \n",
    "        item = response.meta['item']\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        item[\"summ\"] = soup.find(\"span\", class_ = \"summary\").text.replace(\"\\n\", \" \")\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Data**\n",
    "\n",
    "For the purpose of this project, I will be working on data that has already been scraped into a .json file from the spider. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiates file name: file_name\n",
    "file_name = \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>id</th>\n",
       "      <th>loc</th>\n",
       "      <th>pay</th>\n",
       "      <th>summ</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Opus Recruitment Solutions</td>\n",
       "      <td>p_d4996fe3bbcdf3f3</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>120000</td>\n",
       "      <td>My client is a rapidly growing start-up within...</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QBE Insurance</td>\n",
       "      <td>pj_112015665e5a2e01</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>120000</td>\n",
       "      <td>QBE is one of the top 20 global general insure...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xpand</td>\n",
       "      <td>p_95299eb857a58426</td>\n",
       "      <td>Australia</td>\n",
       "      <td>120000</td>\n",
       "      <td>Senior Data Scientist   An exponentially growi...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      company                   id         loc     pay  \\\n",
       "0  Opus Recruitment Solutions   p_d4996fe3bbcdf3f3  Sydney NSW  120000   \n",
       "1               QBE Insurance  pj_112015665e5a2e01  Sydney NSW  120000   \n",
       "2                       Xpand   p_95299eb857a58426   Australia  120000   \n",
       "\n",
       "                                                summ                  title  \n",
       "0  My client is a rapidly growing start-up within...         DATA SCIENTIST  \n",
       "1  QBE is one of the top 20 global general insure...  Senior Data Scientist  \n",
       "2  Senior Data Scientist   An exponentially growi...  Senior Data Scientist  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports file as dataframe: data\n",
    "data = pd.read_json(file_name)\n",
    "\n",
    "# Displays the head of the dataframe\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company    object\n",
       "id         object\n",
       "loc        object\n",
       "pay         int64\n",
       "summ       object\n",
       "title      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company    0\n",
       "id         0\n",
       "loc        0\n",
       "pay        0\n",
       "summ       0\n",
       "title      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d09f4d6de620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Distribution of pay scale for jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Distribution of pay scale for jobs\n",
    "data.pay.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Cleaning Job Titles and Job Summaries**\n",
    "\n",
    "Do to the inconsistencies with the job titles and job summaries, we are going to clean it up a bit. This involves removing all non-alphanumeric characters and making everything lowercase. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Regex to clean\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the outputr is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(text).get_text()\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    #\n",
    "    # 3. Conbert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()\n",
    "    #\n",
    "    # 4.In Python, searching a set is much faster than searching a list, soconvert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    #\n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 6. Join the words back into one string seperated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.summ.map(clean_text);\n",
    "data.title.map(clean_text);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Bag of Words model**\n",
    "\n",
    "Use CountVectorizer to create bag of words for:\n",
    "\n",
    "- Job titles\n",
    "- Job summarys\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6bb7f2978ca3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Fitting the vectorizer on our training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"summary\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Setting the vectorizer just like we would set a model\n",
    "cvec = CountVectorizer(stop_words = \"english\", ngram_range=(2,3))\n",
    "\n",
    "#Fitting the vectorizer on our training data\n",
    "cvec.fit(data[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5893\n"
     ]
    }
   ],
   "source": [
    "print(len(cvec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(cvec.transform(data['summ']).todense(),\n",
    "                      columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5893)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           897\n",
       "experience     624\n",
       "team           459\n",
       "work           414\n",
       "role           359\n",
       "skills         332\n",
       "business       313\n",
       "research       304\n",
       "working        261\n",
       "development    250\n",
       "management     224\n",
       "science        204\n",
       "analytics      202\n",
       "new            201\n",
       "ability        199\n",
       "strong         188\n",
       "analysis       186\n",
       "apply          186\n",
       "australia      185\n",
       "projects       176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_counts = X_train.sum(axis=0)\n",
    "words_counts.sort_values(ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster of words 0:\n",
      " cardiac\n",
      " heart\n",
      " tasmania\n",
      " clinic\n",
      " launceston\n",
      " echo\n",
      " charles\n",
      " imaging\n",
      " north\n",
      " coronary\n",
      "\n",
      "cluster of words 1:\n",
      " data\n",
      " analytics\n",
      " learning\n",
      " experience\n",
      " business\n",
      " machine\n",
      " statistical\n",
      " team\n",
      " science\n",
      " models\n",
      "\n",
      "cluster of words 2:\n",
      " environmental\n",
      " research\n",
      " experience\n",
      " team\n",
      " work\n",
      " australia\n",
      " role\n",
      " data\n",
      " csiro\n",
      " position\n",
      "\n",
      "cluster of words 3:\n",
      " risk\n",
      " financial\n",
      " quantitative\n",
      " markets\n",
      " macquarie\n",
      " trading\n",
      " research\n",
      " analysis\n",
      " marketing\n",
      " credit\n",
      "\n",
      "cluster of words 4:\n",
      " investor\n",
      " project\n",
      " management\n",
      " wholesale\n",
      " property\n",
      " business\n",
      " research\n",
      " macquarie\n",
      " presentations\n",
      " investment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',use_idf=True)\n",
    "model = vectorizer.fit_transform(data['summ'].str.upper())\n",
    "km = KMeans(n_clusters=5,init='k-means++',max_iter=200,n_init=1)\n",
    "\n",
    "k=km.fit(model)\n",
    "terms = vectorizer.get_feature_names()\n",
    "order_centroids = km.cluster_centers_.argsort()[:,::-1]\n",
    "for i in range(5):\n",
    "    print(\"cluster of words %d:\" %i)\n",
    "    for ind in order_centroids[i,:10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Create a predictor matrix of words from the quotes with CountVectorizer\n",
    "\n",
    "It is up to you what ngram range you want to select. **Make sure that `binary=True`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2), max_features=2500, binary=True, stop_words='english')\n",
    "words = cv.fit_transform(data.summ)\n",
    "words = pd.DataFrame(words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>103k</th>\n",
       "      <th>109k</th>\n",
       "      <th>109k 128k</th>\n",
       "      <th>11</th>\n",
       "      <th>11 59pm</th>\n",
       "      <th>...</th>\n",
       "      <th>www macquarie</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>years experience</th>\n",
       "      <th>years professional</th>\n",
       "      <th>years related</th>\n",
       "      <th>years relevant</th>\n",
       "      <th>york</th>\n",
       "      <th>zealand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  02  03  10  100  103k  109k  109k 128k  11  11 59pm   ...     \\\n",
       "0    0   0   0   0    0     0     0          0   0        0   ...      \n",
       "1    0   0   0   0    0     0     0          0   0        0   ...      \n",
       "2    0   0   1   0    0     0     0          0   0        0   ...      \n",
       "3    0   0   0   0    0     0     0          0   0        0   ...      \n",
       "4    1   0   0   0    0     0     0          0   0        0   ...      \n",
       "\n",
       "   www macquarie  year  years  years ago  years experience  \\\n",
       "0              0     1      0          0                 0   \n",
       "1              0     0      0          0                 0   \n",
       "2              0     0      0          0                 0   \n",
       "3              0     0      0          0                 0   \n",
       "4              0     0      1          0                 1   \n",
       "\n",
       "   years professional  years related  years relevant  york  zealand  \n",
       "0                   0              0               0     0        0  \n",
       "1                   0              0               0     0        0  \n",
       "2                   0              0               0     0        0  \n",
       "3                   0              0               0     0        0  \n",
       "4                   0              0               0     0        0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Split pay into high - low.\n",
    "\n",
    "Lets split pay into high - low and see the differences in the words used between the two categories. We're going to split it by median which is ~ $110,000\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"pay_hilo\"] = data[\"pay\"].map(lambda x: 0 if x < 110000 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Split data into training and testing splits\n",
    "\n",
    "You should keep 25% of the data in the test set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2500) (50, 2500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(words.values, data.pay_hilo, test_size=0.25)\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Build a `BernoulliNB` model predicting high vs low salaries from the word appearances\n",
    "\n",
    "The model should only be built (and cross-validated) on the training data.\n",
    "\n",
    "Cross-validate the score and compare it to baseline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "nb.fit(Xtrain, ytrain)\n",
    "\n",
    "nb_scores = cross_val_score(BernoulliNB(), Xtrain, ytrain, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77419355  0.73333333  0.66666667  0.73333333  0.65517241]\n",
      "----------------------------------------------------------------------\n",
      "The average score of a BernoulliNB model is 0.71\n",
      "The baseline score is 0.51\n"
     ]
    }
   ],
   "source": [
    "print(nb_scores)\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"The average score of a BernoulliNB model is {:.2f}\".format(np.mean(nb_scores)))\n",
    "print(\"The baseline score is {:.2f}\".format(np.mean(np.mean(ytrain))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 5. Pull out the probability of words given \"high salary\"\n",
    "\n",
    "The `.feature_log_prob_` attribute of the naive bayes model contains the log probabilities of a feature appearing given a target class.\n",
    "\n",
    "The rows correspond to the class of the target, and the columns correpsond to the features. The first row is the 0 \"low salary\" class, and the second is the 1 \"high salary\" class.\n",
    "\n",
    "#### 5.1 Pull out the log probabilities and convert them to probabilities (for high and low salaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_lp = nb.feature_log_prob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_p = np.exp(feat_lp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_p = np.exp(feat_lp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.2 Make a dataframe with the probabilities and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_probs = pd.DataFrame({'high_p':high_p, 'low_p':low_p, 'feature':words.columns.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>high_p</th>\n",
       "      <th>low_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.065789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature    high_p     low_p\n",
       "0     000  0.064103  0.052632\n",
       "1      02  0.217949  0.105263\n",
       "2      03  0.089744  0.105263\n",
       "3      10  0.025641  0.052632\n",
       "4     100  0.089744  0.065789"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_probs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 5.3 Create a column that is the difference between fresh probability of appearance and rotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_probs['sal_diff'] = feat_probs.high_p - feat_probs.low_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Look at the most likely words for fresh and rotten reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_probs.sort_values('sal_diff', ascending=False, inplace=True)\n",
    "feat_probs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>high_p</th>\n",
       "      <th>low_p</th>\n",
       "      <th>sal_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>based</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>-0.203779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>time</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>-0.191296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>position</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>-0.190621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>management</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-0.168691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>programs</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>-0.159919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>description</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>-0.147773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>click</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.147436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>assist</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>-0.147099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-0.146424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>health</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>-0.133603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>january</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>-0.133266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>address</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>-0.132928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>important</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>-0.132591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>january 2018</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>-0.132591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>communication</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.128880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>professional</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>-0.124494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>candidate</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>-0.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>essential</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>-0.122132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>high level</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>-0.120445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>medical</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>-0.118758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature    high_p     low_p  sal_diff\n",
       "253           based  0.243590  0.447368 -0.203779\n",
       "2291           time  0.269231  0.460526 -0.191296\n",
       "1648       position  0.243590  0.434211 -0.190621\n",
       "1379     management  0.410256  0.578947 -0.168691\n",
       "1743       programs  0.076923  0.236842 -0.159919\n",
       "638     description  0.115385  0.263158 -0.147773\n",
       "368           click  0.102564  0.250000 -0.147436\n",
       "205          assist  0.089744  0.236842 -0.147099\n",
       "19             2018  0.064103  0.210526 -0.146424\n",
       "1055         health  0.076923  0.210526 -0.133603\n",
       "1229        january  0.064103  0.197368 -0.133266\n",
       "77          address  0.051282  0.184211 -0.132928\n",
       "1121      important  0.038462  0.171053 -0.132591\n",
       "1230   january 2018  0.038462  0.171053 -0.132591\n",
       "425   communication  0.397436  0.526316 -0.128880\n",
       "1726   professional  0.230769  0.355263 -0.124494\n",
       "323       candidate  0.166667  0.289474 -0.122807\n",
       "816       essential  0.141026  0.263158 -0.122132\n",
       "1069     high level  0.076923  0.197368 -0.120445\n",
       "1417        medical  0.012821  0.131579 -0.118758"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_probs.sort_values('sal_diff', ascending=True, inplace=True)\n",
    "feat_probs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Examine how your model performs on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "print (nb.score(Xtest, ytest))\n",
    "print (np.mean(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "### 4. Trees Cart Model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 295)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "title_clean = data.title.map(clean_text)\n",
    "word_matrix = cvec.fit_transform(title_clean)\n",
    "word_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 295)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [x.encode('utf8') for x in cvec.get_feature_names()]\n",
    "words_df = pd.DataFrame(columns=columns, data=word_matrix.todense())\n",
    "words_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b'account'</th>\n",
       "      <th>b'acoustic'</th>\n",
       "      <th>b'adelaide'</th>\n",
       "      <th>b'advertising'</th>\n",
       "      <th>b'adviser'</th>\n",
       "      <th>b'agency'</th>\n",
       "      <th>b'agronomist'</th>\n",
       "      <th>b'ai'</th>\n",
       "      <th>b'air'</th>\n",
       "      <th>b'akqa'</th>\n",
       "      <th>...</th>\n",
       "      <th>b'validation'</th>\n",
       "      <th>b'value'</th>\n",
       "      <th>b'vibration'</th>\n",
       "      <th>b'view'</th>\n",
       "      <th>b'water'</th>\n",
       "      <th>b'web'</th>\n",
       "      <th>b'wheat'</th>\n",
       "      <th>b'women'</th>\n",
       "      <th>b'workforce'</th>\n",
       "      <th>b'years'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 295 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b'account'  b'acoustic'  b'adelaide'  b'advertising'  b'adviser'  \\\n",
       "0           0            0            0               0           0   \n",
       "1           0            0            0               0           0   \n",
       "2           0            0            0               0           0   \n",
       "3           0            0            0               0           0   \n",
       "4           0            0            0               0           0   \n",
       "\n",
       "   b'agency'  b'agronomist'  b'ai'  b'air'  b'akqa'    ...     b'validation'  \\\n",
       "0          0              0      0       0        0    ...                 0   \n",
       "1          0              0      0       0        0    ...                 0   \n",
       "2          0              0      0       0        0    ...                 0   \n",
       "3          0              0      0       0        0    ...                 0   \n",
       "4          0              0      0       0        0    ...                 0   \n",
       "\n",
       "   b'value'  b'vibration'  b'view'  b'water'  b'web'  b'wheat'  b'women'  \\\n",
       "0         0             0        0         0       0         0         0   \n",
       "1         0             0        0         0       0         0         0   \n",
       "2         0             0        0         0       0         0         0   \n",
       "3         0             0        0         0       0         0         0   \n",
       "4         0             0        0         0       0         0         0   \n",
       "\n",
       "   b'workforce'  b'years'  \n",
       "0             0         0  \n",
       "1             0         0  \n",
       "2             0         0  \n",
       "3             0         0  \n",
       "4             0         0  \n",
       "\n",
       "[5 rows x 295 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pay_bool = data[\"pay_hilo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54  0.64  0.62  0.58]\n",
      "0.595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Xc = words_df\n",
    "yc = pay_bool\n",
    "\n",
    "cls_scores = cross_val_score(LogisticRegression(), Xc, yc, cv=4)\n",
    "print (cls_scores)\n",
    "print(np.mean(cls_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc1 = DecisionTreeClassifier(max_depth=1)\n",
    "dtc2 = DecisionTreeClassifier(max_depth=2)\n",
    "dtc3 = DecisionTreeClassifier(max_depth=3)\n",
    "dtcN = DecisionTreeClassifier(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc1.fit(Xc, yc)\n",
    "dtc2.fit(Xc, yc)\n",
    "dtc3.fit(Xc, yc)\n",
    "dtcN.fit(Xc, yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54  0.58  0.54  0.52] 0.545\n",
      "[ 0.58  0.6   0.58  0.5 ] 0.565\n",
      "[ 0.58  0.58  0.58  0.5 ] 0.56\n",
      "[ 0.64  0.56  0.58  0.54] 0.58\n"
     ]
    }
   ],
   "source": [
    "dtc1_scores = cross_val_score(dtc1, Xc, yc, cv=4)\n",
    "dtc2_scores = cross_val_score(dtc2, Xc, yc, cv=4)\n",
    "dtc3_scores = cross_val_score(dtc3, Xc, yc, cv=4)\n",
    "dtcN_scores = cross_val_score(dtcN, Xc, yc, cv=4)\n",
    "\n",
    "print (dtc1_scores, np.mean(dtc1_scores))\n",
    "print (dtc2_scores, np.mean(dtc2_scores))\n",
    "print (dtc3_scores, np.mean(dtc3_scores))\n",
    "print (dtcN_scores, np.mean(dtcN_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89000000000000001"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(Xc, yc)\n",
    "logreg.score(Xc, yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "** Grid Search CV **\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = words_df\n",
    "y = data.pay_hilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_params = {\n",
    "    'max_depth':[None,1,2,3,4],\n",
    "    'max_features':[None,'log2','sqrt',2,3,4,5],\n",
    "    'min_samples_split':[2,3,4,5,10,15,20,25,30,40,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dtc_gs = GridSearchCV(DecisionTreeClassifier(), dtc_params, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 385 candidates, totalling 1925 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1925 out of 1925 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [None, 1, 2, 3, 4], 'max_features': [None, 'log2', 'sqrt', 2, 3, 4, 5], 'min_samples_split': [2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': None, 'max_features': 4, 'min_samples_split': 15}\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "dtc_best = dtc_gs.best_estimator_\n",
    "print (dtc_gs.best_params_)\n",
    "print (dtc_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>b'senior'</td>\n",
       "      <td>0.047290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>b'consulting'</td>\n",
       "      <td>0.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>b'backend'</td>\n",
       "      <td>0.025893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b'angular'</td>\n",
       "      <td>0.024194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>b'quality'</td>\n",
       "      <td>0.023221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>b'project'</td>\n",
       "      <td>0.023091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>b'lead'</td>\n",
       "      <td>0.021368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>b'engineer'</td>\n",
       "      <td>0.019336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>b'stack'</td>\n",
       "      <td>0.019108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'analysis'</td>\n",
       "      <td>0.018086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>b'contract'</td>\n",
       "      <td>0.017935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>b'data'</td>\n",
       "      <td>0.016816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>b'postdoctoral'</td>\n",
       "      <td>0.016590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>b'quantitative'</td>\n",
       "      <td>0.015962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'analytics'</td>\n",
       "      <td>0.015844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>b'environmental'</td>\n",
       "      <td>0.015356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b'assurance'</td>\n",
       "      <td>0.014726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>b'transportation'</td>\n",
       "      <td>0.014348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>b'graduate'</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>b'economics'</td>\n",
       "      <td>0.014127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "251          b'senior'    0.047290\n",
       "63       b'consulting'    0.031311\n",
       "31          b'backend'    0.025893\n",
       "15          b'angular'    0.024194\n",
       "223         b'quality'    0.023221\n",
       "219         b'project'    0.023091\n",
       "158            b'lead'    0.021368\n",
       "93         b'engineer'    0.019336\n",
       "258           b'stack'    0.019108\n",
       "11         b'analysis'    0.018086\n",
       "65         b'contract'    0.017935\n",
       "76             b'data'    0.016816\n",
       "206    b'postdoctoral'    0.016590\n",
       "224    b'quantitative'    0.015962\n",
       "14        b'analytics'    0.015844\n",
       "97    b'environmental'    0.015356\n",
       "25        b'assurance'    0.014726\n",
       "280  b'transportation'    0.014348\n",
       "126        b'graduate'    0.014131\n",
       "87        b'economics'    0.014127"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':X.columns,\n",
    "        'importance':dtc_best.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)\n",
    "fi.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
