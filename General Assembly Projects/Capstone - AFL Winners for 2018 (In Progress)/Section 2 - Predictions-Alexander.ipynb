{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting AFL winners using Machine Learning - Predictions\n",
    "\n",
    "---\n",
    "\n",
    "<img src='img/dartboard.jpg'>\n",
    "\n",
    "---\n",
    "\n",
    "Using the data and features created in the previous section **[Section 1 - Feature Preprocessing](Section 1 - Feature Preprocessing.ipynb)**. We are now going to try and use the data to form some predictions regarding the probability of the home the home team winning. \n",
    "\n",
    "In the Notebook below, we will start with a Naive model which only uses the previous year's ladder scores as a predictor and winning team's location as the target. From there we will add:\n",
    "\n",
    "* Information regarding the teams, in the form of dummified team names\n",
    "* Head to Head data from the previous 5 times the two teams have played\n",
    "* Previous game's statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models will be tested under several classification techniques including Logistic Regression, Support Vector Machines (SVM), Random Forest and Gradient Boosting.\n",
    "\n",
    "Following that, we will subject these classifiers to a gridsearch to maximize their accuracy and F1-scores.\n",
    "\n",
    "I have specifically opted to avoid K-Nearest Neighbors as I will be using their predicted probabilities to create personalized odds to compare with the bookies.\n",
    "\n",
    "And finally, we will throw everything into a feed forward Nueral Network and see what we can get out of that. \n",
    "\n",
    "Since the dataset ranges from 2000-2015, in each case we will use years 2000 - 2011 to train and years 2012-2015 to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matches = pd.read_csv(\"data/full_matches_clean.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>premiership</th>\n",
       "      <th>att</th>\n",
       "      <th>win_loc</th>\n",
       "      <th>season</th>\n",
       "      <th>h_prevladder_score</th>\n",
       "      <th>a_prevladder_score</th>\n",
       "      <th>margins_prev_match1</th>\n",
       "      <th>margins_prev_match2</th>\n",
       "      <th>margins_prev_match3</th>\n",
       "      <th>margins_prev_match4</th>\n",
       "      <th>margins_prev_match5</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_odds</th>\n",
       "      <th>away_odds</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009_R12_105_111</td>\n",
       "      <td>0</td>\n",
       "      <td>42087</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>Essendon</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2009-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009_R12_104_116</td>\n",
       "      <td>0</td>\n",
       "      <td>41042</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Collingwood</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2009-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009_R12_106_107</td>\n",
       "      <td>0</td>\n",
       "      <td>33213</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>24</td>\n",
       "      <td>84</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>Fremantle</td>\n",
       "      <td>Geelong</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2009-06-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mid  premiership    att  win_loc  season  h_prevladder_score  \\\n",
       "0  2009_R12_105_111            0  42087        1    2009                  32   \n",
       "1  2009_R12_104_116            0  41042        0    2009                  50   \n",
       "2  2009_R12_106_107            0  33213        0    2009                  24   \n",
       "\n",
       "   a_prevladder_score  margins_prev_match1  margins_prev_match2  \\\n",
       "0                  12                 16.0                  2.0   \n",
       "1                  48                -45.0                -29.0   \n",
       "2                  84                -74.0                 -1.0   \n",
       "\n",
       "   margins_prev_match3  margins_prev_match4  margins_prev_match5  home_team  \\\n",
       "0                -36.0                -10.0                -46.0   Essendon   \n",
       "1                -38.0                -25.0                -19.0     Sydney   \n",
       "2                -68.0                -25.0                -66.0  Fremantle   \n",
       "\n",
       "     away_team  home_odds  away_odds        date  \n",
       "0    Melbourne       1.24       3.93  2009-06-19  \n",
       "1  Collingwood       1.93       1.75  2009-06-20  \n",
       "2      Geelong       7.25       1.08  2009-06-21  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matches.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Before we start anything, we need to first denote a baseline. This is denoted by the probability that the home team wins or \n",
    "Home wins/(Total Games)\n",
    "\n",
    "### $$baseline = \\frac{home\\_wins}{total\\_games}$$\n",
    "\n",
    "The baseline is important as there may be class imbalance, or in other words one of those outcomes may be appear a lot more than the other. When this is the case by simply predicting every entry to be of that class, we will naturally have a high accuracy.\n",
    "\n",
    "As an example. Suppose the home team won 80% of the time. If we predict that the home team wins for every single game, we will naturally have an 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Win Percentages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Home</th>\n",
       "      <td>55.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Away</th>\n",
       "      <td>44.08%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Win Percentages\n",
       "Home          55.92%\n",
       "Away          44.08%"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a table and sets the indexs to \"Home\" and \"Away\" : percentages\n",
    "percentages =  pd.DataFrame(full_matches[\"win_loc\"].value_counts()/len(full_matches[\"win_loc\"]))\n",
    "percentages.index = [\"Home\", \"Away\"]\n",
    "\n",
    "# Formats the entries to 2 decimal place\n",
    "percentages[\"win_loc\"] = percentages[\"win_loc\"].map(lambda x: \"{:.2f}%\".format(x*100))\n",
    "\n",
    "# Changes the columns to \"Win Percentages\"\n",
    "percentages.columns = [\"Win Percentages\"]\n",
    "percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = percentages.loc[\"Home\",\"Win Percentages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6QAAAH7CAYAAADb+FLWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhsn5lrHltGrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf8263b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,8))\n",
    "\n",
    "sns.countplot(full_matches[\"win_loc\"])\n",
    "\n",
    "ax.set_title(\"Outcomes\", fontsize=20)\n",
    "\n",
    "ax.set_xlabel(\"Winning Team\", fontsize=15)\n",
    "ax.set_ylabel(\"Number of Wins\", fontsize=15)\n",
    "ax.set_xticklabels([\"Home\", \"Away\", \"Draw\"], fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code\n",
    "\n",
    "Below is the code that will be used to fit our models, record time taken, and gives an accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = cross_val_predict(clf, features, target, cv=5)\n",
    "    \n",
    "    score = cross_val_score(clf, features, target, cv = 5).mean()\n",
    "    \n",
    "    end = time()\n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred), score\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on F1 score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print (\"F1 score and accuracy score for training set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print (\"F1 score and accuracy score for test set: {:.4f} , {:.4f}.\".format(f1 , acc))\n",
    "    print(\"-----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate predictive models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print (\"Accuracy on the test dataset: %s\" %score)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    #print \"-------------------------------------------------------------------------------------\"\n",
    "    print (\"Confusion matrix\")\n",
    "    print (pd.DataFrame(cm,index=['Benign','Malignant'], columns=['Predicted Benign', 'Predicted Malignant']))\n",
    "    print (\"-------------------------------------------------------------------------------------\")\n",
    "    print (\"Classification report\")\n",
    "    print (classification_report(y_test, y_pred, target_names=['Benign','Malignant']))\n",
    "    print (\"-------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions - Naive Model\n",
    "\n",
    "Lets start with the base model, as you may recall for the basemodel we are only going to be using each team's previous year's ladder score as a predictor.\n",
    "\n",
    "- Predictors - Previous year's ladder score\n",
    "- Target - Win Location (Home vs Away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiates the predictors with columns prevladder scores: X\n",
    "X = full_matches[[\"h_prevladder_score\", \"a_prevladder_score\", \"season\"]]\n",
    "# Initiates the target as winloc: y\n",
    "y = full_matches[\"win_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_prevladder_score</th>\n",
       "      <th>a_prevladder_score</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.763082</td>\n",
       "      <td>-1.844120</td>\n",
       "      <td>-1.712426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.128324</td>\n",
       "      <td>-1.712426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.197147</td>\n",
       "      <td>2.100768</td>\n",
       "      <td>-1.712426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   h_prevladder_score  a_prevladder_score    season\n",
       "0           -0.763082           -1.844120 -1.712426\n",
       "1            0.213565            0.128324 -1.712426\n",
       "2           -1.197147            2.100768 -1.712426"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "Xs = pd.DataFrame(Xs, columns=X.columns)\n",
    "Xs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for the home team winning is 55.92%\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 798. . .\n",
      "Trained model in 0.0040 seconds\n",
      "Made predictions in 0.0836 seconds.\n",
      "F1 score and accuracy score for training set: 0.7191 , 0.6553.\n",
      "Made predictions in 0.0455 seconds.\n",
      "F1 score and accuracy score for test set: 0.7172 , 0.6922.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a SVC using a training set size of 798. . .\n",
      "Trained model in 0.2006 seconds\n",
      "Made predictions in 1.1683 seconds.\n",
      "F1 score and accuracy score for training set: 0.6981 , 0.6227.\n",
      "Made predictions in 0.1416 seconds.\n",
      "F1 score and accuracy score for test set: 0.7000 , 0.6847.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a GradientBoostingClassifier using a training set size of 798. . .\n",
      "Trained model in 0.3267 seconds\n",
      "Made predictions in 1.4956 seconds.\n",
      "F1 score and accuracy score for training set: 0.6857 , 0.6277.\n",
      "Made predictions in 0.8801 seconds.\n",
      "F1 score and accuracy score for test set: 0.6199 , 0.6128.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0025 seconds\n",
      "Made predictions in 0.0400 seconds.\n",
      "F1 score and accuracy score for training set: 0.6036 , 0.5664.\n",
      "Made predictions in 0.0300 seconds.\n",
      "F1 score and accuracy score for test set: 0.6498 , 0.6243.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0265 seconds\n",
      "Made predictions in 0.3492 seconds.\n",
      "F1 score and accuracy score for training set: 0.6818 , 0.6178.\n",
      "Made predictions in 0.2802 seconds.\n",
      "F1 score and accuracy score for test set: 0.6255 , 0.6392.\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_lr      = LogisticRegression(penalty='l2', solver=\"liblinear\")\n",
    "clf_svc     = SVC(kernel = 'rbf', probability = True)\n",
    "clf_xgboost = GradientBoostingClassifier()\n",
    "clf_forest   = RandomForestClassifier()\n",
    "clf_tree    = DecisionTreeClassifier()\n",
    "\n",
    "print(\"The baseline score for the home team winning is {}\\n\".format(baseline))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "train_predict(clf_lr, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_svc, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_xgboost, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_tree, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_forest, X_train, y_train, X_test, y_test)\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Naive Model\n",
    "\n",
    "From just the naive model alone, it appears to do roughly 10% better than the baseline, with Logistic Regression only slightly out-performing the SVC\n",
    "\n",
    "Classifier         |Accuracy  |F1-Score  |\n",
    ":--                |:--       |:--       |\n",
    "Logistic Regression|**67.67%**|  71.52%  |\n",
    "SVC                |66.17%    |**71.70%**|\n",
    "Gradient Boosting  |62.78%    |67.55%    |\n",
    "Decision Tree      |54.89%    |57.35%    |\n",
    "Random Forest      |56.02%    |63.60%    |\n",
    "\n",
    "\n",
    "Lets keep adding to the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions - Naive + Teams\n",
    "\n",
    "In this model, we're going to dummify the teams for both the home and away games and add them to the model. This will add a little bit of general details regarding each team such as any possible rivalries.\n",
    "\n",
    "We will be using patsy to assist with the dummification of the teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "features = '~ h_prevladder_score + a_prevladder_score + season + premiership + C(home_team) + C(away_team) -1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiates the predictors: X\n",
    "X = patsy.dmatrix(features, data=full_matches, return_type='dataframe')\n",
    "# Initiates the target as winloc: y\n",
    "y = full_matches[\"win_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C(home_team)[Adelaide]</th>\n",
       "      <th>C(home_team)[Carlton]</th>\n",
       "      <th>C(home_team)[Collingwood]</th>\n",
       "      <th>C(home_team)[Essendon]</th>\n",
       "      <th>C(home_team)[Fremantle]</th>\n",
       "      <th>C(home_team)[Geelong]</th>\n",
       "      <th>C(home_team)[Gold Coast]</th>\n",
       "      <th>C(home_team)[Hawthorn]</th>\n",
       "      <th>C(home_team)[Melbourne]</th>\n",
       "      <th>C(home_team)[North Melbourne]</th>\n",
       "      <th>...</th>\n",
       "      <th>C(away_team)[T.Port Adelaide]</th>\n",
       "      <th>C(away_team)[T.Richmond]</th>\n",
       "      <th>C(away_team)[T.St Kilda]</th>\n",
       "      <th>C(away_team)[T.Sydney]</th>\n",
       "      <th>C(away_team)[T.West Coast]</th>\n",
       "      <th>C(away_team)[T.Western Bulldogs]</th>\n",
       "      <th>h_prevladder_score</th>\n",
       "      <th>a_prevladder_score</th>\n",
       "      <th>season</th>\n",
       "      <th>premiership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.261291</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.27931</td>\n",
       "      <td>3.888600</td>\n",
       "      <td>-0.255079</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.212571</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263338</td>\n",
       "      <td>-0.252982</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>-0.763082</td>\n",
       "      <td>-1.844120</td>\n",
       "      <td>-1.712426</td>\n",
       "      <td>-0.228961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.261291</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.27931</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.255079</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.212571</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263338</td>\n",
       "      <td>-0.252982</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>0.213565</td>\n",
       "      <td>0.128324</td>\n",
       "      <td>-1.712426</td>\n",
       "      <td>-0.228961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.261291</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.27931</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>3.920361</td>\n",
       "      <td>-0.27735</td>\n",
       "      <td>-0.212571</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>-0.248749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263338</td>\n",
       "      <td>-0.252982</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>-0.265372</td>\n",
       "      <td>-0.257162</td>\n",
       "      <td>-0.259233</td>\n",
       "      <td>-1.197147</td>\n",
       "      <td>2.100768</td>\n",
       "      <td>-1.712426</td>\n",
       "      <td>-0.228961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C(home_team)[Adelaide]  C(home_team)[Carlton]  C(home_team)[Collingwood]  \\\n",
       "0               -0.261291              -0.257162                   -0.27931   \n",
       "1               -0.261291              -0.257162                   -0.27931   \n",
       "2               -0.261291              -0.257162                   -0.27931   \n",
       "\n",
       "   C(home_team)[Essendon]  C(home_team)[Fremantle]  C(home_team)[Geelong]  \\\n",
       "0                3.888600                -0.255079               -0.27735   \n",
       "1               -0.257162                -0.255079               -0.27735   \n",
       "2               -0.257162                 3.920361               -0.27735   \n",
       "\n",
       "   C(home_team)[Gold Coast]  C(home_team)[Hawthorn]  C(home_team)[Melbourne]  \\\n",
       "0                 -0.212571               -0.265372                -0.248749   \n",
       "1                 -0.212571               -0.265372                -0.248749   \n",
       "2                 -0.212571               -0.265372                -0.248749   \n",
       "\n",
       "   C(home_team)[North Melbourne]     ...       C(away_team)[T.Port Adelaide]  \\\n",
       "0                      -0.248749     ...                           -0.263338   \n",
       "1                      -0.248749     ...                           -0.263338   \n",
       "2                      -0.248749     ...                           -0.263338   \n",
       "\n",
       "   C(away_team)[T.Richmond]  C(away_team)[T.St Kilda]  C(away_team)[T.Sydney]  \\\n",
       "0                 -0.252982                 -0.259233               -0.265372   \n",
       "1                 -0.252982                 -0.259233               -0.265372   \n",
       "2                 -0.252982                 -0.259233               -0.265372   \n",
       "\n",
       "   C(away_team)[T.West Coast]  C(away_team)[T.Western Bulldogs]  \\\n",
       "0                   -0.257162                         -0.259233   \n",
       "1                   -0.257162                         -0.259233   \n",
       "2                   -0.257162                         -0.259233   \n",
       "\n",
       "   h_prevladder_score  a_prevladder_score    season  premiership  \n",
       "0           -0.763082           -1.844120 -1.712426    -0.228961  \n",
       "1            0.213565            0.128324 -1.712426    -0.228961  \n",
       "2           -1.197147            2.100768 -1.712426    -0.228961  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "Xs = pd.DataFrame(Xs, columns=X.columns)\n",
    "Xs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for high paying jobs is 55.92%\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 798. . .\n",
      "Trained model in 0.0220 seconds\n",
      "Made predictions in 0.1481 seconds.\n",
      "F1 score and accuracy score for training set: 0.6979 , 0.6441.\n",
      "Made predictions in 0.0996 seconds.\n",
      "F1 score and accuracy score for test set: 0.6690 , 0.6510.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a SVC using a training set size of 798. . .\n",
      "Trained model in 0.4113 seconds\n",
      "Made predictions in 1.9969 seconds.\n",
      "F1 score and accuracy score for training set: 0.6758 , 0.6127.\n",
      "Made predictions in 0.4658 seconds.\n",
      "F1 score and accuracy score for test set: 0.7027 , 0.6694.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a GradientBoostingClassifier using a training set size of 798. . .\n",
      "Trained model in 0.2342 seconds\n",
      "Made predictions in 1.7648 seconds.\n",
      "F1 score and accuracy score for training set: 0.6866 , 0.6352.\n",
      "Made predictions in 1.0367 seconds.\n",
      "F1 score and accuracy score for test set: 0.6360 , 0.6318.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0060 seconds\n",
      "Made predictions in 0.0660 seconds.\n",
      "F1 score and accuracy score for training set: 0.6316 , 0.5739.\n",
      "Made predictions in 0.0355 seconds.\n",
      "F1 score and accuracy score for test set: 0.6050 , 0.5788.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0315 seconds\n",
      "Made predictions in 0.3638 seconds.\n",
      "F1 score and accuracy score for training set: 0.6599 , 0.6052.\n",
      "Made predictions in 0.2577 seconds.\n",
      "F1 score and accuracy score for test set: 0.6791 , 0.6582.\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_lr      = LogisticRegression(penalty='l2', solver=\"liblinear\")\n",
    "clf_svc     = SVC(kernel = 'rbf', probability = True)\n",
    "clf_xgboost = GradientBoostingClassifier()\n",
    "clf_forest   = RandomForestClassifier()\n",
    "clf_tree    = DecisionTreeClassifier()\n",
    "\n",
    "print(\"The baseline score for high paying jobs is {}\\n\".format(baseline))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "train_predict(clf_lr, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_svc, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_xgboost, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_tree, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_forest, X_train, y_train, X_test, y_test)\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results - Naive + Teams\n",
    "\n",
    "Interesting, besides SVC taking a small hit to both F1-score and accuracy, the others all have increased slightly with Logistic still being ahead by 4%\n",
    "\n",
    "Classifier         |Accuracy  |F1-Score  |\n",
    ":--                |:--       |:--       |\n",
    "Logistic Regression|**71.43%**|**73.97%**|\n",
    "SVC                |65.04%    |69.10%    |\n",
    "Gradient Boosting  |67.29%    |70.30%    |\n",
    "Decision Tree      |57.17%    |59.86%    |\n",
    "Random Forest      |59.40%    |62.50%    |\n",
    "\n",
    "It appears that the simplicity of Decision Trees seem to struggle with datasets of higher dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions - Adding Head-to-Head\n",
    "\n",
    "From here, we're going to try adding the margins for the two teams into the frey. The idea behind Head-to-Head data is further reinforce rivalries between pairs of teams, where for one reason or another a specific team doesnt perform well against another. **Such as 2017 Swans against Hawthorn.**\n",
    "\n",
    "<img src='img/sadswan.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "features = '~ h_prevladder_score + a_prevladder_score + premiership + margins_prev_match1 + margins_prev_match2 + \\\n",
    "            + margins_prev_match3 + margins_prev_match4 + margins_prev_match5 + C(home_team) + C(away_team) -1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiates the predictors: X\n",
    "X = patsy.dmatrix(features, data=full_matches, return_type='dataframe')\n",
    "# Initiates the target as winloc: y\n",
    "y = full_matches[\"win_loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "Xs = pd.DataFrame(Xs, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline score for high paying jobs is 55.92%\n",
      "\n",
      "-----------------------------------------------------------------------\n",
      "Training a LogisticRegression using a training set size of 798. . .\n",
      "Trained model in 0.0160 seconds\n",
      "Made predictions in 0.1316 seconds.\n",
      "F1 score and accuracy score for training set: 0.6925 , 0.6415.\n",
      "Made predictions in 0.0580 seconds.\n",
      "F1 score and accuracy score for test set: 0.6691 , 0.6549.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a SVC using a training set size of 798. . .\n",
      "Trained model in 0.3913 seconds\n",
      "Made predictions in 1.9374 seconds.\n",
      "F1 score and accuracy score for training set: 0.6758 , 0.6127.\n",
      "Made predictions in 0.2512 seconds.\n",
      "F1 score and accuracy score for test set: 0.7014 , 0.6774.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a GradientBoostingClassifier using a training set size of 798. . .\n",
      "Trained model in 0.2797 seconds\n",
      "Made predictions in 2.1295 seconds.\n",
      "F1 score and accuracy score for training set: 0.6717 , 0.6152.\n",
      "Made predictions in 1.1828 seconds.\n",
      "F1 score and accuracy score for test set: 0.6944 , 0.6766.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a DecisionTreeClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0115 seconds\n",
      "Made predictions in 0.0996 seconds.\n",
      "F1 score and accuracy score for training set: 0.6156 , 0.5827.\n",
      "Made predictions in 0.0455 seconds.\n",
      "F1 score and accuracy score for test set: 0.6736 , 0.6352.\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "Training a RandomForestClassifier using a training set size of 798. . .\n",
      "Trained model in 0.0345 seconds\n",
      "Made predictions in 0.3913 seconds.\n",
      "F1 score and accuracy score for training set: 0.6157 , 0.5902.\n",
      "Made predictions in 0.2677 seconds.\n",
      "F1 score and accuracy score for test set: 0.6937 , 0.7180.\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_lr      = LogisticRegression(penalty='l2', solver=\"liblinear\")\n",
    "clf_svc     = SVC(kernel = 'rbf', probability = True)\n",
    "clf_xgboost = GradientBoostingClassifier()\n",
    "clf_forest  = RandomForestClassifier()\n",
    "clf_tree    = DecisionTreeClassifier()\n",
    "\n",
    "print(\"The baseline score for high paying jobs is {}\\n\".format(baseline))\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "train_predict(clf_lr, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_svc, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_xgboost, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_tree, X_train, y_train, X_test, y_test)\n",
    "print ('')\n",
    "train_predict(clf_forest, X_train, y_train, X_test, y_test)\n",
    "print ('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch - Helper code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python36-32\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\program files (x86)\\python36-32\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def gridsearch(model, params):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function simplifies the process of a gridsearch by taking parameters and a model. It searches over a 5 cross\\\n",
    "    validations and prints out the best parameters that it's found as well as the best score\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initiates a 5-fold gridsearch with specified params\n",
    "    gs = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # Fits the gridsearch to the standardized predictors and target\n",
    "    gs.fit(Xs,y)\n",
    "    \n",
    "    # Displays the best parameters it has found and its corresponding accuracy\n",
    "    print (\"------------------------------------------------------------------------------------\")\n",
    "    print (\"Best parameters: {}\".format(gs.best_params_))\n",
    "    print (\"Best accuracy score before splitting and training dataset: {:.2f}%\\n\".format(gs.best_score_*100))\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print (\"Accuracy on the test dataset: {:.2f}%\".format(score*100))\n",
    "    con_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print (\"Confusion matrix\")\n",
    "    print (pd.DataFrame(con_matrix,index=['Away Team Wins','Home Team Wins'], columns=['Predicted Away', 'Predicted Home']))\n",
    "    print (\"\\n-------------------------------------------------------------------------------------\")\n",
    "    print (\"Classification report\\n\")\n",
    "    print (classification_report(y_test, y_pred, target_names=['Away Team','Home Team']))\n",
    "    print (\"-------------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print (\"Best accuracy score on the testing dataset: {:.2f}%\\n\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch - Logistic Regression\n",
    "\n",
    "**Pros:** \n",
    "    - Number of features, which are non-correlated, used in the model don't impact performance\n",
    "\n",
    "**Cons:** \n",
    "    - Requires a large enough sample size\n",
    "\n",
    "--- \n",
    "\n",
    "Since our dataset is based on a boolean result of a home or away team winning, logistic regression would be an \n",
    "appropriate method for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Grid Search\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Best parameters: {'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best accuracy score before splitting and training dataset: 66.73%\n",
      "\n",
      "Accuracy on the test dataset: 72.18%\n",
      "Confusion matrix\n",
      "                Predicted Away  Predicted Home\n",
      "Away Team Wins              96              28\n",
      "Home Team Wins              46              96\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Away Team       0.68      0.77      0.72       124\n",
      "  Home Team       0.77      0.68      0.72       142\n",
      "\n",
      "avg / total       0.73      0.72      0.72       266\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Best accuracy score on the testing dataset: 72.18%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch parameters for Logistic Regression\n",
    "lr_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver' : ['liblinear'],\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'class_weight' : [None, 'balanced'],\n",
    "}\n",
    "\n",
    "print(\"Logistic Regression with Grid Search\\n\")\n",
    "\n",
    "# Gridsearchs over the given parameters\n",
    "gs_lr = gridsearch(clf_lr, lr_params)\n",
    "\n",
    "# Displays the findings\n",
    "evaluate_model(gs_lr.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch - Decision tree\n",
    "\n",
    "**Pros:**\n",
    "    - Easy to interpret \n",
    "    - Good accuracy for less than a dozen features, which is the case after we have reduced dimension\n",
    "    - Can handle feature interactions, unlike regression, i.e. collinearity. Although, in our case, we have removed collinearity. \n",
    "    \n",
    "**Cons:**\n",
    "    - Larger trees with more than a dozen features reduces performance\n",
    "    - It could be impossible to plan for all contingancies, i.e. features that are not in the dataset. For purposes of this exercise, we assume that the features in our dataset is good enough for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Grid Search\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Best parameters: {'class_weight': None, 'max_depth': 3, 'min_samples_split': 2}\n",
      "Best accuracy score before splitting and training dataset: 64.29%\n",
      "\n",
      "Accuracy on the test dataset: 62.41%\n",
      "Confusion matrix\n",
      "                Predicted Away  Predicted Home\n",
      "Away Team Wins              53              71\n",
      "Home Team Wins              29             113\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Away Team       0.65      0.43      0.51       124\n",
      "  Home Team       0.61      0.80      0.69       142\n",
      "\n",
      "avg / total       0.63      0.62      0.61       266\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Best accuracy score on the testing dataset: 62.41%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch parameters for Decision Trees\n",
    "tree_params = {\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'class_weight':[None, 'balanced']\n",
    "}\n",
    "\n",
    "\n",
    "print (\"Decision Tree with Grid Search\\n\")\n",
    "\n",
    "# Gridsearchs over the given parameters\n",
    "gs_tree = gridsearch(clf_tree, tree_params)\n",
    "\n",
    "# Displays the findings\n",
    "evaluate_model(gs_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch - Gradient Descent\n",
    "\n",
    "**Pros:**\n",
    "    - Outperforms other models \n",
    "    \n",
    "**Cons:**\n",
    "    - Difficult to interpret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree with Grid Search\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Best parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
      "Best accuracy score before splitting and training dataset: 64.76%\n",
      "\n",
      "Accuracy on the test dataset: 66.17%\n",
      "Confusion matrix\n",
      "                Predicted Away  Predicted Home\n",
      "Away Team Wins              70              54\n",
      "Home Team Wins              36             106\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Away Team       0.66      0.56      0.61       124\n",
      "  Home Team       0.66      0.75      0.70       142\n",
      "\n",
      "avg / total       0.66      0.66      0.66       266\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Best accuracy score on the testing dataset: 66.17%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch parameters for Decision Trees\n",
    "xgboost_params = {\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "print (\"Decision Tree with Grid Search\\n\")\n",
    "\n",
    "# Gridsearchs over the given parameters\n",
    "gs_xgboost = gridsearch(clf_xgboost, xgboost_params)\n",
    "\n",
    "# Displays the findings\n",
    "evaluate_model(gs_xgboost.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch - Random Forest\n",
    "**Pros:**\n",
    "    - Reduces chances of overfitting compared to decision trees because they take the average of several trees, which could lead to improved accuracy compared to decision trees. In this case, given that we have taken care of overfitting with grid search for decision trees, this may not be the case. \n",
    "\n",
    "**Cons:**\n",
    "    - Unlike decision trees, the classifications made by random forests are difficult for humans to interpret\n",
    "    - Features with categorical variables, which is NOT the case in this dataset, random forests could be more biased towards features with more levels \n",
    "    - If the dataset contains groups of correlations between features, which again is NOT the case in this dataset, random forests can favour the groups with a smaller number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Grid Search\n",
      "\n",
      "------------------------------------------------------------------------------------\n",
      "Best parameters: {'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5}\n",
      "Best accuracy score before splitting and training dataset: 65.70%\n",
      "\n",
      "Accuracy on the test dataset: 69.55%\n",
      "Confusion matrix\n",
      "                Predicted Away  Predicted Home\n",
      "Away Team Wins              66              58\n",
      "Home Team Wins              23             119\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Away Team       0.74      0.53      0.62       124\n",
      "  Home Team       0.67      0.84      0.75       142\n",
      "\n",
      "avg / total       0.70      0.70      0.69       266\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "Best accuracy score on the testing dataset: 69.55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch Parameters for Random Forest\n",
    "forest_params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'class_weight':[None, 'balanced']\n",
    "}\n",
    "\n",
    "\n",
    "print (\"Random Forest with Grid Search\\n\")\n",
    "\n",
    "# Gridserachs over the given parameters\n",
    "gs_forest = gridsearch(clf_forest, forest_params)\n",
    "\n",
    "# Displays the finding\n",
    "evaluate_model(gs_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch -  Support Vector Machine\n",
    "**Pros:**\n",
    "    - Accuracy\n",
    "    - Works well on smaller and cleaner datasets.\n",
    "\n",
    "**Cons:**\n",
    "    - Isn’t suited to larger datasets as the training time with SVMs can be high."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Gridsearch Parameters for Support Vector Machines\n",
    "svm_params = [{'kernel': ['rbf'],\n",
    "               'gamma': [1e-3, 1e-4],\n",
    "               'C': [1, 10, 100, 1000]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "print (\"Support Vector Machines with Grid Search\\n\")\n",
    "\n",
    "# Gridsearchs over the given parameters\n",
    "gs_svm = gridsearch(clf_svc, svm_params)\n",
    "\n",
    "# Displays the findings\n",
    "evaluate_model(gs_svm.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Section 2 Predictions - Findings\n",
    "\n",
    "---\n",
    "\n",
    "From the gridsearches done it appears that Logistic Regression marginally outperformed the rest with an accuracy of 67.29%, while this is not absurdly high, it is roughly 10% higher than the baseline of 55.92%.\n",
    "\n",
    "As mentioned previously, in Section 3, we will use the calculated probabilities from Logistic Regression to calculate odds from each game which will than be compared to the bookies odds.\n",
    "\n",
    "In the remainder of Section 2 we will look at how our full model fairs when working with data in 5 year blocks. This means that we will train our model on data for 4 years before testing it on the 5th. This is crucial as there have been discussions which have suggested that the playstyle of AFL games have shifted within the last decade.\n",
    "\n",
    "We will also attempt to pass our dataset through a Neural Network to see how it fairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "features = '~ season + h_prevladder_score + a_prevladder_score + premiership + margins_prev_match1 + margins_prev_match2 + \\\n",
    "            + margins_prev_match3 + margins_prev_match4 + margins_prev_match5 + C(home_team) + C(away_team) -1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiates the predictors: X\n",
    "X = patsy.dmatrix(features, data=full_matches, return_type='dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiates the target as winloc: y\n",
    "y = full_matches[[\"season\", \"win_loc\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_year_pred(clf, X, y, year):\n",
    "    \n",
    "    X_train = X[(X[\"season\"] >= year-5) & (X[\"season\"] <= year-1)].drop([\"season\"], axis=1)\n",
    "    X_test  = X[X[\"season\"] == year].drop([\"season\"], axis=1)\n",
    "    y_train = y[(y[\"season\"] >= year-5) & (y[\"season\"] <= year-1)][\"win_loc\"]\n",
    "    y_test  = y[y[\"season\"] == year][\"win_loc\"]\n",
    "    \n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    predictions =  clf.predict_proba(X_test)\n",
    "    \n",
    "    year_data = full_matches[full_matches[\"season\"] == year]\n",
    "\n",
    "    cols_to_keep = [\"mid\", \"win_loc\", \"season\", \"home_team\", \"away_team\", \"home_odds\", \"away_odds\"]\n",
    "    year_data = year_data[cols_to_keep].reset_index(drop=True)\n",
    "    \n",
    "    probs_df = pd.DataFrame(predictions, columns = [\"away_myodds\", \"home_myodds\"])\n",
    "    probs_df = probs_df[[\"home_myodds\", \"away_myodds\"]]\n",
    "    \n",
    "    probs_df[\"home_myodds\"] = probs_df[\"home_myodds\"].apply(lambda x: 1/x)\n",
    "    probs_df[\"away_myodds\"] = probs_df[\"away_myodds\"].apply(lambda x: 1/x)\n",
    "\n",
    "    probs_df = probs_df.round({'away_myodds': 2, 'home_myodds': 2})\n",
    "    year_odds_comparison = year_data.join(probs_df, how=\"outer\")\n",
    "    \n",
    "    \n",
    "\n",
    "    return year_odds_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf_lr      = LogisticRegression(penalty='l2', solver=\"liblinear\")\n",
    "clf_svc     = SVC(kernel = 'rbf', probability = True)\n",
    "clf_xgboost = GradientBoostingClassifier()\n",
    "clf_forest  = RandomForestClassifier()\n",
    "clf_tree    = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a LogisticRegression using a training set size of 582. . .\n",
      "Trained model in 0.0070 seconds\n",
      "Made predictions in 0.0761 seconds.\n",
      "F1 score and accuracy score for training set: 0.7241 , 0.6699.\n",
      "Made predictions in 0.0430 seconds.\n",
      "F1 score and accuracy score for test set: 0.6703 , 0.6339.\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "predictions = five_year_pred(clf_lr, X, y, year = 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "Which leads us to actually using what we've created to attempt some predicting.\n",
    "\n",
    "Low and Behold **[Section 3 - Tipping](Section 3 - Tipping.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
